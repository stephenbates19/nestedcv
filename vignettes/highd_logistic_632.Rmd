---
title: "632 IF estimator"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{632 IF estimator}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---


```{r}
library(glmnet)
```


```{r}
################################################
#### Harrel setup (hihg-dimensional logistic regression)
################################################

### Problem setting
n <- 90
p <- 1000
k <- 4 #number of nonzeros
alpha <- .1 #nominal error rate, total across both tails.

# create the design matrix 
set.seed(1)
X <- matrix(rnorm(n = n * p), nrow = n)

#sample Y from a logistic model
strength <- 1 #signal strength
beta = strength * c(rep(1, k), rep(0, p - k))

#determine bayes error with this beta vector
set.seed(555)
n_holdout <- 5000
X_holdout <- matrix(rnorm(n_holdout * p), nrow = n_holdout)
p_holdout <- 1 / (1 + exp(-X_holdout %*% beta))
Y_holdout <- (runif(n_holdout) < p_holdout) * 1.0
bayes_error <- (rowSums(X_holdout[, 1:k]) < 0) * (Y_holdout == 1) + (rowSums(X_holdout[, 1:k]) > 0) * (Y_holdout == 0)

# Bayes error rate
error_rate <- mean(bayes_error)
print(error_rate)

#Fit one model to find a good lambda. This lambda will be fixed in future simulations.
set.seed(1)
probs <- 1 / (1 + exp(-strength * X %*% beta))
Y <- (runif(n) < probs) * 1.0
fit <- cv.glmnet(X, Y, family = "binomial")
lambdas <- fit$lambda
best_lam <- match(fit$lambda.min, lambdas)
best_lam
lambdas[best_lam]

funcs_params = list("lambdas" = lambdas, "best_lam" = best_lam)
################################################
```


```{r}
#using the .632 code to get an estimate of prediction error and SE

#helper functions
misclass_loss <- function(y1, y2, funcs_params = NA) {
  y1 != y2
} 

fitter_glmnet_logistic <- function(X, Y, idx = NA, funcs_params = NA) {
  if(sum(is.na(idx)) > 0) {idx <- 1:nrow(X)}
  fit <- glmnet(X[idx, ], Y[idx], family = "binomial", lambda = funcs_params$lambdas) #assumes lambda is in global env
  
  fit
}

predictor_glmnet_logistic <- function(fit, X_new, funcs_params = NA) {
  beta_hat <- fit$beta[, funcs_params$best_lam] #assumes best_lam is in global env
  a0_hat <- fit$a0[funcs_params$best_lam]
  preds <- (X_new %*% beta_hat + a0_hat > 0)
  
  preds
} 

logistic_lasso_funs <- list(fitter = fitter_glmnet_logistic,
                            predictor = predictor_glmnet_logistic,
                            loss = misclass_loss,
                            name = "logistic_lasso")
```

```{r}
#run the .632 bootstrap
set.seed(1)
t1 <- Sys.time()
out <- boot632(x = X, y = Y, nboot = 1000, 
                 funcs = logistic_lasso_funs,
               funcs_params = list("lambdas" = lambdas, "best_lam" = best_lam))
print(Sys.time() - t1)
out 
```

```{r}
#using the .632 code to get an estimate of prediction error and SE
n_sim <- 10
set.seed(5555)

boot_results <- list()
errs <- c()

t1 <- Sys.time()
for(i in 1:n_sim){
  print(i)
  
  X <- matrix(rnorm(n = n * p), nrow = n)
  probs <- 1 / (1 + exp(-strength * X %*% beta))
  Y <- (runif(n) < probs) * 1.0
  out <- boot632(x = X, y = Y, nboot = 500, 
                 funcs = logistic_lasso_funs,
                 funcs_params = funcs_params)
  
  fit <- fitter_glmnet_logistic(X, Y, funcs_params = funcs_params)
  pred <- predictor_glmnet_logistic(fit, X_holdout, funcs_params = funcs_params)
  errs <- c(errs, mean(misclass_loss(pred, Y_holdout)))
  
  boot_results[[i]] <- out
}
print(Sys.time() - t1)

#save(errs, boot_results, file = "../lowd_632_ex.RData")
#load(file = "../lowd_632_ex.RData")

#conservative estimate of SE of .632 estimator
se_hats <- unlist(lapply(boot_results, function(x){x$se_est}))
err_632 <- unlist(lapply(boot_results, function(x){x$err_hat}))
se_naive <- unlist(lapply(boot_results, function(x){x$sd}))

alpha <- .2
q_val <- qnorm(1 - alpha/2)

#err of .632 estimator
mean(err_632 + q_val * se_hats < errs)
mean(err_632 - q_val * se_hats > errs)

plot(errs, err_632)
```
